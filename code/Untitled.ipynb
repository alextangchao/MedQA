{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00732b5-273d-47c4-938a-a51a7384ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from datasets import load_dataset, Dataset,DatasetDict\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02366ae5-5f6b-418e-8fa3-6c84de6d5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"e2ab1b2b4244272268524960c98f9a9e6a5decd6\"\n",
    "os.environ[\"WANDB_PROJECT\"]=\"ft\"\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9279e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# sweep_configuration = {\n",
    "#     \"method\": \"random\",\n",
    "#     \"name\": \"sweep\",\n",
    "#     \"metric\": {\"goal\": \"minimize\", \"name\": \"score\"},\n",
    "#     \"parameters\": {\n",
    "#         # \"batch_size\": {\"values\": [16, 32, 64]},\n",
    "#         \"epochs\": {\"values\": [2, 4, 6]},\n",
    "#         \"lr\": {\"max\": 5e-4, \"min\": 1e-5},\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1269d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "modelpath=r\"/tsukimi/llm/Meta-Llama-3-8B/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False)   \n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859c65bf-2703-4977-9b86-1c75d462c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"Amirkid/MedQuad-dataset\")\n",
    "all_train_data = []\n",
    "for i in range(0,len(train_dataset[\"train\"]),2):\n",
    "    all_train_data.append(f'Question:\\n{train_dataset[\"train\"][i][\"text\"]} \\n\\nAnswer:\\n{train_dataset[\"train\"][i+1][\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16683e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({\"text\": all_train_data}).train_test_split(test_size=0.1)\n",
    "# dataset['validation'] = dataset['test']\n",
    "# del dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f5e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_path = '/workdir/MedQA/data/test_set.csv'\n",
    "# test_dataset = load_dataset(\"csv\", data_files=test_data_path)['train']\n",
    "\n",
    "# all_test_data = []\n",
    "# for test_data in test_dataset:\n",
    "#     all_test_data.append(f\"Question:\\n{test_data['question']} \\n\\nAnswer:\\n{test_data['answer']}\")\n",
    "# dataset['test']= Dataset.from_dict({\"text\": all_test_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992f13ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7b33221a5f48bdad0f3bd50a9a0b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/14760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9390aafcbe74de1bb987421fad5d15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dateset_tokenized = dataset.map(\n",
    "    lambda examples: tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512),\n",
    "    batched=True, \n",
    "    num_proc=4,   \n",
    "    remove_columns=[\"text\"])  \n",
    "\n",
    "dataset = dateset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dc6ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78a630b194c48ca9b044143f8911944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    device_map=\"auto\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    ),\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b643db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=64, \n",
    "    lora_alpha=16, \n",
    "    target_modules = ['q_proj', 'k_proj', 'down_proj', 'v_proj', 'gate_proj', 'o_proj', 'up_proj'],\n",
    "    lora_dropout=0.1, \n",
    "    bias=\"none\", \n",
    "    modules_to_save = [\"lm_head\", \"embed_tokens\"],\t\t# needed because we added new tokens to tokenizer/model\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd84090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.integrations import WandbCallback\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def decode_predictions(tokenizer, predictions):\n",
    "    labels = tokenizer.batch_decode(predictions.label_ids)\n",
    "    logits = predictions.predictions.argmax(axis=-1)\n",
    "    prediction_text = tokenizer.batch_decode(logits)\n",
    "    return {\"labels\": labels, \"predictions\": prediction_text}\n",
    "\n",
    "\n",
    "class WandbPredictionProgressCallback(WandbCallback):\n",
    "    \"\"\"Custom WandbCallback to log model predictions during training.\n",
    "\n",
    "    This callback logs model predictions and labels to a wandb.Table at each \n",
    "    logging step during training. It allows to visualize the \n",
    "    model predictions as the training progresses.\n",
    "\n",
    "    Attributes:\n",
    "        trainer (Trainer): The Hugging Face Trainer instance.\n",
    "        tokenizer (AutoTokenizer): The tokenizer associated with the model.\n",
    "        sample_dataset (Dataset): A subset of the validation dataset \n",
    "          for generating predictions.\n",
    "        num_samples (int, optional): Number of samples to select from \n",
    "          the validation dataset for generating predictions. Defaults to 100.\n",
    "        freq (int, optional): Frequency of logging. Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, trainer, tokenizer, val_dataset,\n",
    "                 num_samples=100, freq=2):\n",
    "        \"\"\"Initializes the WandbPredictionProgressCallback instance.\n",
    "\n",
    "        Args:\n",
    "            trainer (Trainer): The Hugging Face Trainer instance.\n",
    "            tokenizer (AutoTokenizer): The tokenizer associated \n",
    "              with the model.\n",
    "            val_dataset (Dataset): The validation dataset.\n",
    "            num_samples (int, optional): Number of samples to select from \n",
    "              the validation dataset for generating predictions.\n",
    "              Defaults to 100.\n",
    "            freq (int, optional): Frequency of logging. Defaults to 2.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.trainer = trainer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sample_dataset = val_dataset.select(range(num_samples))\n",
    "        self.freq = freq\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        super().on_evaluate(args, state, control, **kwargs)\n",
    "        # control the frequency of logging by logging the predictions\n",
    "        # every `freq` epochs\n",
    "        if state.epoch % self.freq == 0:\n",
    "            # generate predictions\n",
    "            predictions = self.trainer.predict(self.sample_dataset)\n",
    "            # decode predictions and labels\n",
    "            predictions = decode_predictions(self.tokenizer, predictions)\n",
    "            # add predictions to a wandb.Table\n",
    "            predictions_df = pd.DataFrame(predictions)\n",
    "            predictions_df[\"epoch\"] = state.epoch\n",
    "            records_table = self._wandb.Table(dataframe=predictions_df)\n",
    "            # log the table to wandb\n",
    "            self._wandb.log({\"sample_predictions\": records_table})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c024374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(elements):\n",
    "    tokenlist=[e[\"input_ids\"] for e in elements]\n",
    "    tokens_maxlen=max([len(t) for t in tokenlist])\n",
    "\n",
    "    input_ids,labels,attention_masks = [],[],[]\n",
    "    for tokens in tokenlist:\n",
    "        pad_len=tokens_maxlen-len(tokens)\n",
    "\n",
    "        # pad input_ids with pad_token, labels with ignore_index (-100) and set attention_mask 1 where content otherwise 0\n",
    "        input_ids.append( tokens + [tokenizer.pad_token_id]*pad_len )   \n",
    "        labels.append( tokens + [-100]*pad_len )    \n",
    "        attention_masks.append( [1]*len(tokens) + [0]*pad_len ) \n",
    "\n",
    "    batch={\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"labels\": torch.tensor(labels),\n",
    "        \"attention_mask\": torch.tensor(attention_masks)\n",
    "    }\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6070ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/transformers/src/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bs=8      # batch size\n",
    "ga_steps=1  # gradient acc. steps\n",
    "epochs=5\n",
    "steps_per_epoch=len(dataset[\"train\"])//(bs*ga_steps)\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/tsukimi/llm/ft\",\n",
    "    report_to='wandb',  \n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    eval_steps=steps_per_epoch,\t\t# eval and save once per epoch  \t\n",
    "    save_steps=steps_per_epoch,\n",
    "    gradient_accumulation_steps=ga_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    learning_rate=0.0005,\n",
    "    group_by_length=True,\n",
    "    fp16=True,\n",
    "    ddp_find_unused_parameters=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "model=model,\n",
    "tokenizer=tokenizer,\n",
    "data_collator=collate,\n",
    "train_dataset=dataset[\"train\"],\n",
    "eval_dataset=dataset[\"test\"],\n",
    "args=args,\n",
    ")\n",
    "\n",
    "progress_callback = WandbPredictionProgressCallback(\n",
    "    trainer=trainer,\n",
    "    tokenizer=tokenizer,\n",
    "    val_dataset=dataset[\"test\"],\n",
    "    num_samples=10,\n",
    "    freq=2,\n",
    ")\n",
    "trainer.add_callback(progress_callback)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "057cdfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcalvinchai\u001b[0m (\u001b[33mcalvin-chai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20240504_000454-9140khac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/calvin-chai/ft/runs/9140khac' target=\"_blank\">star-speeder-17</a></strong> to <a href='https://wandb.ai/calvin-chai/ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/calvin-chai/ft' target=\"_blank\">https://wandb.ai/calvin-chai/ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/calvin-chai/ft/runs/9140khac' target=\"_blank\">https://wandb.ai/calvin-chai/ft/runs/9140khac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /tsukimi/llm/Meta-Llama-3-8B/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "No inf checks were recorded for this optimizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:1875\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:2269\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2268\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 2269\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/optimizer.py:136\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_patched_step_method\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called:\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;66;03m# If the optimizer step was skipped, gradient overflow was detected.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/amp/grad_scaler.py:449\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m OptState\u001b[38;5;241m.\u001b[39mREADY:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n",
      "\u001b[0;31mAssertionError\u001b[0m: No inf checks were recorded for this optimizer."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc880312",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb08544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(config=None):\n",
    "#   with wandb.init(config=config):\n",
    "#     # set sweep configuration\n",
    "#     config = wandb.config\n",
    "\n",
    "#     bs=16\n",
    "\n",
    "#     # set training arguments\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=\"/tsukimi/llm/ft\",\n",
    "# \treport_to='wandb',  # Turn on Weights & Biases logging\n",
    "#         num_train_epochs=config.epochs,\n",
    "#         learning_rate=config.learning_rate,\n",
    "#         # weight_decay=config.weight_decay,\n",
    "#         per_device_train_batch_size=bs,\n",
    "#         per_device_eval_batch_size=bs,\n",
    "#         save_strategy='epoch',\n",
    "#         evaluation_strategy='epoch',\n",
    "#         logging_strategy='epoch',\n",
    "#         load_best_model_at_end=True,\n",
    "#         remove_unused_columns=False,\n",
    "#         fp16=True\n",
    "#     )\n",
    "#     trainer = Trainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=collate,\n",
    "#     train_dataset=dataset[\"train\"],\n",
    "#     eval_dataset=dataset[\"validation\"],\n",
    "#     test_dataset=dataset[\"test\"],\n",
    "#     args=training_args,\n",
    "# )\n",
    "\n",
    "#     progress_callback = WandbPredictionProgressCallback(\n",
    "#         trainer=trainer,\n",
    "#         tokenizer=tokenizer,\n",
    "#         val_dataset=dataset[\"validation\"],\n",
    "#         num_samples=10,\n",
    "#         freq=2,\n",
    "#     )\n",
    "#     trainer.add_callback(progress_callback)\n",
    "\n",
    "\n",
    "#     # start training loop\n",
    "#     trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5h5njsmy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0004154122001904217\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcalvinchai\u001b[0m (\u001b[33mcalvin-chai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20240503_230942-5h5njsmy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/calvin-chai/ft/runs/5h5njsmy' target=\"_blank\">stilted-sweep-1</a></strong> to <a href='https://wandb.ai/calvin-chai/ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/calvin-chai/ft/sweeps/ril7zg3t' target=\"_blank\">https://wandb.ai/calvin-chai/ft/sweeps/ril7zg3t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/calvin-chai/ft' target=\"_blank\">https://wandb.ai/calvin-chai/ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/calvin-chai/ft/sweeps/ril7zg3t' target=\"_blank\">https://wandb.ai/calvin-chai/ft/sweeps/ril7zg3t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/calvin-chai/ft/runs/5h5njsmy' target=\"_blank\">https://wandb.ai/calvin-chai/ft/runs/5h5njsmy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_config.py\", line 162, in __getattr__\n",
      "    return self.__getitem__(key)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'learning_rate'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17249/4270920747.py\", line 13, in train\n",
      "    learning_rate=config.learning_rate,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_config.py\", line 164, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'learning_rate'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_config.py\", line 162, in __getattr__\n",
      "    return self.__getitem__(key)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'learning_rate'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17249/4270920747.py\", line 13, in train\n",
      "    learning_rate=config.learning_rate,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_config.py\", line 164, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'learning_rate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py\", line 2313, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py\", line 2561, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/lib/mailbox.py\", line 283, in wait\n",
      "    found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/lib/mailbox.py\", line 130, in _get_and_clear\n",
      "    if self._wait(timeout=timeout):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/lib/mailbox.py\", line 126, in _wait\n",
      "    return self._event.wait(timeout=timeout)\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 306, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "Exception\n"
     ]
    }
   ],
   "source": [
    "# wandb.agent(sweep_id, train, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bs=8      # batch size\n",
    "# ga_steps=1  # gradient acc. steps\n",
    "# epochs=5\n",
    "# steps_per_epoch=len(dataset[\"train\"])//(bs*ga_steps)\n",
    "\n",
    "# args = TrainingArguments(\n",
    "    \n",
    "    \n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     logging_steps=1,\n",
    "#     eval_steps=steps_per_epoch,\t\t# eval and save once per epoch  \t\n",
    "#     save_steps=steps_per_epoch,\n",
    "#     gradient_accumulation_steps=ga_steps,\n",
    "#     num_train_epochs=epochs,\n",
    "#     lr_scheduler_type=\"constant\",\n",
    "#     optim=\"paged_adamw_32bit\",\n",
    "#     learning_rate=0.0002,\n",
    "#     group_by_length=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# trainer.train()\n",
    "# model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab08f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02d3cc30453b49f4b7db4931efaf70d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_2019d4e9096b4934bcde8316f35aceed",
       "style": "IPY_MODEL_057f38afd26442c0ba6d9d5aadf680c4"
      }
     },
     "057f38afd26442c0ba6d9d5aadf680c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "077e070c36e1449d8d7060802dba50db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_89809f044fc649e4bcaeb65957a839b7",
       "max": 1,
       "style": "IPY_MODEL_da434bde5452402784e58da1624ac4ff"
      }
     },
     "0d6ce9aa5e404e77b5d95d38b0480f73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a1d6772153e24ac2aaa2e1be2da50801",
       "style": "IPY_MODEL_f2c43ec28af945e1af7d9cefec4a8b56",
       "value": " 1/1 [00:00&lt;00:00, 269.92it/s]"
      }
     },
     "0eade166f05b47ecb5639febc2ab8d7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "10e7ec31ea5641d7bb6a6aff60568b0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_da293799aa264e0188e72ab3cc3b6867",
       "style": "IPY_MODEL_bae17278f49843cc93893067f1918b8e",
       "value": " 2479/0 [00:00&lt;00:00, 57707.82 examples/s]"
      }
     },
     "122997437edf47d9a40d12771972215f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "14752658296745b1b7757ab462945f38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "15e64f309375455eb37562e286300f41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9c67750804f04dfeb8a011e101a64db1",
        "IPY_MODEL_df92c05ccfda4024909d05e5a04a5d86",
        "IPY_MODEL_55b06d9e5d5a4a0b93d7784a129a227f"
       ],
       "layout": "IPY_MODEL_6bbc56c64f834f89b50bb3ed0306314a"
      }
     },
     "2019d4e9096b4934bcde8316f35aceed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "227d453e12cc4b8298505eed0bd8cde6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "23ea8b14216b45b8b354cefadab57a48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "26a27509d1bf4127877c8c16d9719973": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3ed8871ce2a64588bc6b3550d4d9578b",
        "IPY_MODEL_28af1e758c2f4e88b768191de30c1a1b",
        "IPY_MODEL_10e7ec31ea5641d7bb6a6aff60568b0e"
       ],
       "layout": "IPY_MODEL_a284beef6d274b5ebd5700b6c3be81b0"
      }
     },
     "28af1e758c2f4e88b768191de30c1a1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_abf86b0a83a44e4fbdbb6188ba6c6772",
       "max": 1,
       "style": "IPY_MODEL_b2fa0298b19046fcbd5edda2d3d5038b",
       "value": 1
      }
     },
     "2e05726cc508422897777f3bd0d48502": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "315856a51f7c4be9812bb2cad5414192": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_eb83395328da41ecae1996acaffbb86d",
       "style": "IPY_MODEL_896a1bcd9d1344b3a87aae1d25f6d570",
       "value": " 360/360 [00:00&lt;00:00, 65.0kB/s]"
      }
     },
     "31e11886daad4ec4abb818fb366e250c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4cf63b72a4dc47a081fc2e4f51e3c954",
       "style": "IPY_MODEL_77ea0b1fd4094272b559812f336eb205",
       "value": "Downloading data: 100%"
      }
     },
     "3542d7e9fb2042ef9982f543bf4eea99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3567d137b3584c82863eeb5c7b4dea19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_31e11886daad4ec4abb818fb366e250c",
        "IPY_MODEL_b0005df86fa04769bebb20ec9b775592",
        "IPY_MODEL_454fae4026e241a1bfc87e68e9a54fbf"
       ],
       "layout": "IPY_MODEL_3a68e51a65cb42f296b3896e4ca60afc"
      }
     },
     "3a68e51a65cb42f296b3896e4ca60afc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3ed8871ce2a64588bc6b3550d4d9578b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a3219f8b50a54d2eb19a841d5b151529",
       "style": "IPY_MODEL_23ea8b14216b45b8b354cefadab57a48",
       "value": "Generating train split: "
      }
     },
     "403c9ca8130a445ca3f9db5068ccac10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3542d7e9fb2042ef9982f543bf4eea99",
       "max": 1,
       "style": "IPY_MODEL_8182d0df187b46e88bbbb20d638e7723",
       "value": 1
      }
     },
     "454fae4026e241a1bfc87e68e9a54fbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ed2bd99d667144868cbf990073d702ad",
       "style": "IPY_MODEL_f1de683c0ac944b6bedbb675e95b2545",
       "value": " 8.76M/8.76M [00:01&lt;00:00, 7.28MB/s]"
      }
     },
     "4cf63b72a4dc47a081fc2e4f51e3c954": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4d6eaa8027d548628016833f522749cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4ff202d17fb14a918c9fefca5d8d52e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "531e32f7aaf04e4592da6de332d20ab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7080fa770de145969cd314fcef3d73ef",
        "IPY_MODEL_7a64ef859d714f5f980a30d2d31c25f1",
        "IPY_MODEL_315856a51f7c4be9812bb2cad5414192"
       ],
       "layout": "IPY_MODEL_14752658296745b1b7757ab462945f38"
      }
     },
     "55b06d9e5d5a4a0b93d7784a129a227f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8a79f291ea9c41dd99ede9002b8fa592",
       "style": "IPY_MODEL_e2f611fa4db64e1eb56439db989c3226",
       "value": " 32800/32800 [00:00&lt;00:00, 577856.44 examples/s]"
      }
     },
     "58a78a7299a24535b0ab7ef178ca2096": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5d4733c4d1de498b98849d84b00c8f45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a84177ee17c14d23a4e0a3b0bca30fea",
       "max": 1,
       "style": "IPY_MODEL_f7a01525e92442eca104218b30995d4f",
       "value": 1
      }
     },
     "630a667cb1dc428a885903210726d5e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_c2d466717f174a878c6f53f45dd34a4f",
       "style": "IPY_MODEL_ac2655cbefa345dfa2e10cfbb1375c93",
       "value": "0.012 MB of 0.012 MB uploaded\r"
      }
     },
     "6450e6c14dbe4f0badb48f79ada7173d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_905cabb3f3734a2d80851e22c7c22e4c",
       "style": "IPY_MODEL_b059998e3e9e42c3b6ccd24cdc942cd5",
       "value": "Computing checksums: 100%"
      }
     },
     "656d5a599e764f6e9f23cb39462e686d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6a19ffeba3cd452db70a37bb6d4e542a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_7a5dc3e77eb248c6add4b0d5c7a8f0a4",
       "max": 1,
       "style": "IPY_MODEL_bee56649f2af42479f20b995a12d14d2",
       "value": 1
      }
     },
     "6bbc56c64f834f89b50bb3ed0306314a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e1c013381aa45d2a9285a45c65d7d62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4ff202d17fb14a918c9fefca5d8d52e1",
       "style": "IPY_MODEL_c840f572574a4a9f8ac2681c91f9e0ff",
       "value": "Computing checksums: 100%"
      }
     },
     "7080fa770de145969cd314fcef3d73ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e1131e897e264ea5849ce60cb7eae03d",
       "style": "IPY_MODEL_227d453e12cc4b8298505eed0bd8cde6",
       "value": "Downloading readme: 100%"
      }
     },
     "77ea0b1fd4094272b559812f336eb205": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7a5dc3e77eb248c6add4b0d5c7a8f0a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7a64ef859d714f5f980a30d2d31c25f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4d6eaa8027d548628016833f522749cf",
       "max": 360,
       "style": "IPY_MODEL_656d5a599e764f6e9f23cb39462e686d",
       "value": 360
      }
     },
     "8182d0df187b46e88bbbb20d638e7723": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "896a1bcd9d1344b3a87aae1d25f6d570": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "89809f044fc649e4bcaeb65957a839b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8a79f291ea9c41dd99ede9002b8fa592": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8c4442723f624ed7b9fc0b4ded991ec0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "905cabb3f3734a2d80851e22c7c22e4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "98c4d15ca2e74895bf7e83fd010b6f63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9c67750804f04dfeb8a011e101a64db1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0eade166f05b47ecb5639febc2ab8d7c",
       "style": "IPY_MODEL_2e05726cc508422897777f3bd0d48502",
       "value": "Generating train split: 100%"
      }
     },
     "a1d6772153e24ac2aaa2e1be2da50801": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a284beef6d274b5ebd5700b6c3be81b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a3219f8b50a54d2eb19a841d5b151529": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a84177ee17c14d23a4e0a3b0bca30fea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "abf86b0a83a44e4fbdbb6188ba6c6772": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "ac2655cbefa345dfa2e10cfbb1375c93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "b0005df86fa04769bebb20ec9b775592": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_8c4442723f624ed7b9fc0b4ded991ec0",
       "max": 8756796,
       "style": "IPY_MODEL_cc3b7419f16d4a4a9ae634a9b80f4f02",
       "value": 8756796
      }
     },
     "b059998e3e9e42c3b6ccd24cdc942cd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b2fa0298b19046fcbd5edda2d3d5038b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bae17278f49843cc93893067f1918b8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bc4a5905c681424e8aaf7e2929ed6668": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bee56649f2af42479f20b995a12d14d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c2d466717f174a878c6f53f45dd34a4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c747885a59b041f7b57a6ff69a0e1576": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c840f572574a4a9f8ac2681c91f9e0ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc3b7419f16d4a4a9ae634a9b80f4f02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "da293799aa264e0188e72ab3cc3b6867": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "da434bde5452402784e58da1624ac4ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "df92c05ccfda4024909d05e5a04a5d86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e9727e8c1956436c9e2fd49abd64fd40",
       "max": 32800,
       "style": "IPY_MODEL_c747885a59b041f7b57a6ff69a0e1576",
       "value": 32800
      }
     },
     "e1131e897e264ea5849ce60cb7eae03d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1673423794b43f09d04cb3d47d9587e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_58a78a7299a24535b0ab7ef178ca2096",
       "style": "IPY_MODEL_f63a3bd731884e3883afd8aac29ec4bc",
       "value": " 1/1 [00:00&lt;00:00, 252.79it/s]"
      }
     },
     "e2f611fa4db64e1eb56439db989c3226": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e6f474e02d094ee5a286d6c19bda3505": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6450e6c14dbe4f0badb48f79ada7173d",
        "IPY_MODEL_403c9ca8130a445ca3f9db5068ccac10",
        "IPY_MODEL_e1673423794b43f09d04cb3d47d9587e"
       ],
       "layout": "IPY_MODEL_98c4d15ca2e74895bf7e83fd010b6f63"
      }
     },
     "e9727e8c1956436c9e2fd49abd64fd40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eacbd2911817452fb67d364541326be5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_02d3cc30453b49f4b7db4931efaf70d7",
        "IPY_MODEL_077e070c36e1449d8d7060802dba50db"
       ],
       "layout": "IPY_MODEL_bc4a5905c681424e8aaf7e2929ed6668"
      }
     },
     "eb83395328da41ecae1996acaffbb86d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ed2bd99d667144868cbf990073d702ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f0e8a71022c24e24a5fe693cbc010606": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f1de683c0ac944b6bedbb675e95b2545": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f2c43ec28af945e1af7d9cefec4a8b56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f5e902ca4e184acb99028f86128d1689": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6e1c013381aa45d2a9285a45c65d7d62",
        "IPY_MODEL_5d4733c4d1de498b98849d84b00c8f45",
        "IPY_MODEL_0d6ce9aa5e404e77b5d95d38b0480f73"
       ],
       "layout": "IPY_MODEL_f0e8a71022c24e24a5fe693cbc010606"
      }
     },
     "f63a3bd731884e3883afd8aac29ec4bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f7a01525e92442eca104218b30995d4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
